---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash-pra-deployment
  namespace: monitor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: logstash-pra
  template:
    metadata:
      labels:
        app: logstash-pra
    spec:
      initContainers:
      - name: sync-archive-logs
        image: rclone/rclone:latest
        volumeMounts:
          - name: s3-pra-log-mirror
            mountPath: /var/log/s3
        command:
        - /bin/sh
        args:
        - -c
        - |
          set -e;
          LOG_DIR=/var/log/s3/
          if [ "${SCW_LOG_GZIP}" == "true" ]; then
            rclone -v copy --checkers=8 --transfers=8 --ignore-existing s3:${SCW_LOG_ARCHIVE_BUCKET} ${LOG_DIR};
          fi;
        env:
        - name: RCLONE_CONFIG_S3_TYPE
          value: s3
        - name: RCLONE_CONFIG_S3_ENV_AUTH
          value: "false"
        - name: RCLONE_CONFIG_S3_ENDPOINT
          value: s3.${SCW_REGION}.scw.cloud
        - name: RCLONE_CONFIG_S3_REGION
          value: ${SCW_REGION}
        - name: RCLONE_CONFIG_S3_SERVER_SIDE_ENCRYPTION
          value: ""
        - name: RCLONE_CONFIG_S3_FORCE_PATH_STYLE
          value: "false"
        - name: RCLONE_CONFIG_S3_LOCATION_CONSTRAINT
          value: ""
        - name: RCLONE_CONFIG_S3_STORAGE_CLASS
          value: ""
        - name: RCLONE_CONFIG_S3_ACL
          value: private
        - name: RCLONE_CONFIG_S3_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: s3-log-keys
              key: AWS_ACCESS_KEY_ID
        - name: RCLONE_CONFIG_S3_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: s3-log-keys
              key: AWS_SECRET_ACCESS_KEY
      - name: fix-permissions
        image: busybox
        command:
        - sh
        - -c
        - |
          chown -R 1000 /usr/share/logstash/data/plugins
        volumeMounts:
        - name: logstash-pra-data-plugins
          mountPath: /usr/share/logstash/data/plugins
      containers:
      - name: logstash-pra
        image: docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}
        ports:
        - containerPort: 5044
        env:
          - name: ELASTIC_PASSWORD
            valueFrom:
              secretKeyRef:
                name: ${APP_GROUP}-es-elastic-user
                key: elastic
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: s3-log-keys
                key: AWS_ACCESS_KEY_ID
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: s3-log-keys
                key: AWS_SECRET_ACCESS_KEY
        volumeMounts:
          - name: config-volume
            mountPath: /usr/share/logstash/config
          - name: logstash-pra-pipeline-volume
            mountPath: /usr/share/logstash/pipeline
          - name: cert-ca
            mountPath: /etc/logstash/certificates
            readOnly: true
          - name: s3-pra-log-mirror
            readOnly: true
            mountPath: /var/log/s3
          - name: logstash-pra-data-plugins
            readOnly: false
            mountPath: /usr/share/logstash/data/plugins
      volumes:
      - name: config-volume
        configMap:
          name: logstash-pra-configmap
          items:
            - key: logstash.yml
              path: logstash.yml
      - name: logstash-pra-pipeline-volume
        configMap:
          name: logstash-pra-configmap
          items:
            - key: logstash.conf
              path: logstash.conf
      - name: cert-ca
        secret:
          secretName: monitor-es-http-certs-public
      - name: s3-pra-log-mirror
        persistentVolumeClaim:
          claimName: s3-pra-log-mirror
      - name: logstash-pra-data-plugins
        persistentVolumeClaim:
          claimName: logstash-pra-data-plugins
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-pra-configmap
  namespace: monitor
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
    pipeline.ecs_compatibility: disabled
  logstash.conf: |
    input {
      file {
        type => "gzip"
        path => "/var/log/s3/**/*.jsonl.gz"
        mode => "read"
        file_completed_action => "log"
        file_completed_log_path => "/usr/share/logstash/data/plugins/inputs/file/completed_archive.log"
        file_sort_direction => "desc"
        file_sort_by => "path"
        # exit_after_read => true ## this fail as reread all after logstash restart
        discover_interval => 1000000000
        stat_interval => 1000000000
        codec => "json"
      }
    }
    filter {
      date {
        match => [ "date" , "ISO8601" ]
      }
      mutate {
        add_field => {
          "source" => "%{[path]}"
        }
      }
      grok {
        match => {
          "[source]" => ".*/(?<kubernetes_cluster_name>judilibre-scw-[^\/]*)-(master|dev)/.*$"
        }
        tag_on_failure => [ "kubernetes_cluster_name_error" ]
      }
      if "kubernetes_cluster_name_error" in [tags] {
        mutate {
          add_field => { "kubernetes_cluster_name" => "default" }
        }
      }
      mutate {
        rename => {
          "[kubernetes_labels][app]" => "[kubernetes_labels][app.kubernetes.io/name]"
        }
      }
      if [cpu_p] or [Mem.total] or [write_size] {
        mutate {
          add_field => { "log_type" => "metrics" }
        }
      } else {
        if [kubernetes_container_name] == "nginx-ingress-controller" or [kubernetes_namespace_name] =~ /^judilibre/ {
          grok {
            match => {
              "log" => "%{TIMESTAMP_ISO8601:container_timestamp} %{WORD:container_output} %{WORD:container_output_mode} %{GREEDYDATA:container_log}"
            }
            tag_on_failure => [ "kubernetes_log_parse_error" ]
          }
          if [container_output] {
              mutate {
                remove_field => ["log"]
              }
            if [container_output] == "stderr" {
              mutate {
                add_tag => ["container_error"]
              }
            }
            if [kubernetes_container_name] == "nginx-ingress-controller" {
              if [container_output] != "stderr" {
                mutate {
                  add_field => { "log_type" => "web_access" }
                }
                grok {
                  match => { "container_log" => "%{IPORHOST:clientip} (?:-|(%{WORD}.%{WORD})) (-|%{USER:http_user}) \[%{HTTPDATE:timestamp_request}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" (-|%{NUMBER:status;long}) (-|%{NUMBER:body_bytes_sent;long}) (?:\"(?:%{URI:http_referrer}|-)\") \"%{DATA:http_user_agent}\" (-|%{NUMBER:request_length;long}) (-|%{NUMBER:request_time;double}) \[(?:%{DATA:proxy_upstream_name})\] \[(?:%{DATA:proxy_alternative_upstream_name})\] (-|%{NOTSPACE:upstream_addr}|(?<upstream_addr>(\d+.\d+.\d+.\d+:\d+(, )?|-)+)) (-|%{NUMBER:upstream_response_length;long}|(?<upstream_response_length>(\d+(, )?|-)+)) (-|%{NUMBER:upstream_response_time;double}|(?<upstream_response_time>([0-9\.]+(, )?|-)+)) (-|%{NUMBER:upstream_status;long}|(?<upstream_status>(\d+(, )?|-)+)) %{NOTSPACE:request_id}" }
                }
                if "_grokparsefailure" in [tags] {
                  mutate {
                    add_tag => [ "nginx_log_parse_error" ]
                  }
                } else {
                  mutate {
                    remove_field => ["container_log"]
                    convert => {
                      body_bytes_sent => integer
                      request_length => integer
                      request_time => float
                    }
                  }
                  grok {
                    match => [ "request", "%{URIPARAM:request_params}" ]
                  }
                  if [request_params] {
                    mutate {
                      gsub => [ "request_params", "(\?|\[\]|\/)", "" ]
                      gsub => [ "request_params", "\+", " " ]
                      lowercase => [ "request_params" ]
                    }
                    urldecode {
                      field => "request_params"
                    }
                    kv {
                      prefix => "request_params_"
                      source => "request_params"
                      field_split => "&"
                    }
                  }
                  geoip {
                    source => "clientip"
                  }
                  if [proxy_upstream_name] =~ /search/ {
                    grok {
                      match => {
                        "[request]" => "^/(?<request_api>(decision|search|taxonomy|stats|healthcheck)).*"
                      }
                      tag_on_failure => [ "request_invalid" ]
                    }
                  } else if [proxy_upstream_name] =~ /admin/ {
                    grok {
                      match => {
                        "[request]" => "^/(?<request_api>(admin|delete|import|index)).*"
                      }
                      tag_on_failure => [ "request_invalid" ]
                    }
                  }
                }
              } else {
                mutate {
                  add_field => { "log_type" => "web_error" }
                }
              }
            } else {
              if [kubernetes_container_name] == "nginx-ingress-controller" {
                mutate {
                  add_field => { "log_type" => "web_error" }
                }
              } else {
                mutate {
                  add_field => { "log_type" => "judilibre" }
                }
              }
            }
          } else {
            mutate {
              add_field => { "log_type" => "judilibre" }
            }
          }
        } else {
          drop {}
        }
      }
    }
    output {
      elasticsearch {
        index => "logstash-%{[kubernetes_cluster_name]}-%{[log_type]}-%{+YYYY.MM}"
        user => "elastic"
        password => "${ELASTIC_PASSWORD}"
        hosts => ["https://monitor-es-http:9200"]
        cacert => "/etc/logstash/certificates/ca.crt"
        ssl => true
        action => "create"
      }
    }
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: s3-pra-log-mirror
  namespace: monitor
  labels:
    app: logstash-pra
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: logstash-pra-data-plugins
  namespace: monitor
  labels:
    app: logstash-pra
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi